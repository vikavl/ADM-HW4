{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":77759,"sourceType":"datasetVersion","datasetId":339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Homework 4 (ADM) - Movie Recommendation System\n\nAuthor: Viktoriia Vlasenko  \n\nEmail: [vlasenko.2088928@studenti.uniroma1.it](mailto:vlasenko.2088928@studenti.uniroma1.it)\n\n***","metadata":{}},{"cell_type":"markdown","source":"## 1. Recommendation System with LSH\n\nIn this section, you will implement a recommendation system by identifying users with similar preferences and suggesting movies based on their behavior. \nSpecifically, you will implement your version of the [**LSH algorithm**](https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/).","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Data Preparation\n\nDownload the MovieLens dataset from [here](https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset?select=rating.csv). After downloading, explore the dataset to understand the structure and identify any preprocessing steps needed.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport random\nimport time\nfrom tqdm import tqdm\nimport asyncio\nfrom tqdm.asyncio import tqdm\nfrom itertools import combinations\nfrom sklearn.metrics import mean_absolute_error, precision_recall_fscore_support\nfrom collections import defaultdict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:28.550151Z","iopub.execute_input":"2024-12-08T22:03:28.550785Z","iopub.status.idle":"2024-12-08T22:03:29.477821Z","shell.execute_reply.started":"2024-12-08T22:03:28.550750Z","shell.execute_reply":"2024-12-08T22:03:29.476777Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Load Data**","metadata":{}},{"cell_type":"code","source":"movie = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/movie.csv\")\nmovie.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:30.385737Z","iopub.execute_input":"2024-12-08T22:03:30.386911Z","iopub.status.idle":"2024-12-08T22:03:30.455529Z","shell.execute_reply.started":"2024-12-08T22:03:30.386863Z","shell.execute_reply":"2024-12-08T22:03:30.454564Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['movieId', 'title', 'genres'], dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"rating = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/rating.csv\")\nrating.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:32.095774Z","iopub.execute_input":"2024-12-08T22:03:32.096472Z","iopub.status.idle":"2024-12-08T22:03:51.194448Z","shell.execute_reply.started":"2024-12-08T22:03:32.096434Z","shell.execute_reply":"2024-12-08T22:03:51.193570Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### 1.2 Minhash Signatures\n\nUsing the `userId` and `movieId` columns, implement your own MinHash function. This function will hash each user's watched movie list, creating a representation that allows for quick comparisons of user similarities.\n\n- **Important:** Implement your MinHash function from scratch—**do not use any pre-built hash functions.**\n- Use your MinHash function to generate signature vectors for each user based on their rated movies.\n- Experiment with different hash functions and threshold values to find the most effective configurations. Report these results.\n- Read the class materials and, if necessary, conduct an internet search. The description of hash functions in the [book](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf) may be helpful as a reference.","metadata":{}},{"cell_type":"code","source":"user_movie_map = rating.groupby('userId')['movieId'].apply(set)\nuser_movie_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T15:19:34.818779Z","iopub.execute_input":"2024-12-08T15:19:34.819211Z","iopub.status.idle":"2024-12-08T15:19:46.824891Z","shell.execute_reply.started":"2024-12-08T15:19:34.819172Z","shell.execute_reply":"2024-12-08T15:19:46.823888Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"userId\n1         {2, 3081, 4105, 1036, 5146, 541, 29, 32, 4128,...\n2         {3, 260, 2948, 2951, 1544, 1673, 266, 908, 245...\n3         {512, 1, 3072, 2053, 2054, 2567, 1544, 2571, 1...\n4         {6, 519, 520, 10, 19, 531, 32, 420, 165, 548, ...\n5         {2, 515, 260, 1028, 648, 11, 140, 141, 780, 10...\n                                ...                        \n138489    {2571, 2959, 912, 2324, 2455, 1562, 29, 1061, ...\n138490    {1543, 3079, 2573, 2575, 17, 529, 531, 1041, 2...\n138491    {1, 8961, 33794, 3608, 4128, 2722, 2085, 2857,...\n138492    {2054, 2571, 21, 2599, 5673, 1073, 6711, 58, 2...\n138493    {1, 2, 2050, 2051, 69644, 2065, 18, 19, 2078, ...\nName: movieId, Length: 138493, dtype: object"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"`generate_diverse_hash_functions` is genereting different types of hash functions for creating the signatures. I picked 10 types of different function and randomly generated the coefficients for them.\n\nSince I am using random approach for creatiung hash function there is no need in further shuffling the hash functions.","metadata":{}},{"cell_type":"code","source":"def generate_diverse_hash_functions(num_hashes=10, max_value=1000):\n    \"\"\"\n    Generate diverse hash functions for MinHash experimentation.\n    \"\"\"\n    hash_functions = []\n    for i in range(num_hashes):\n        # Generate random coefficients for the hash functions\n        a = random.randint(1, max_value)\n        b = random.randint(0, max_value)\n        c = random.randint(0, max_value)\n        p = max_value + 1  # Use a large prime\n\n        # Linear hash function\n        hash_functions.append(lambda x, a=a, b=b, p=p: (a * x + b) % p)\n        \n        # Quadratic hash function\n        hash_functions.append(lambda x, a=a, b=b, c=c, p=p: (a * x**2 + b * x + c) % p)\n        \n        # Cubic hash function\n        hash_functions.append(lambda x, a=a, b=b, c=c, p=p: (a * x**3 + b * x**2 + c) % p)\n        \n        # Modulo-based hash function\n        hash_functions.append(lambda x, a=a, b=b, p=p: ((x + a) * (x + b)) % p)\n        \n        # XOR-based hash function\n        hash_functions.append(lambda x, a=a, p=p: (a ^ x) % p)\n        \n        # Composite hash function\n        hash_functions.append(lambda x, a=a, b=b, p=p: ((a * x) + b) // 2 % p)\n        \n        # Logarithmic-based hash function\n        hash_functions.append(lambda x, a=a, p=p: int((a * (1 + x).bit_length()) % p))\n        \n        # Exponential-based hash function\n        hash_functions.append(lambda x, a=a, p=p: int((a * (2 ** x)) % p))\n        \n        # Prime shift hash function\n        hash_functions.append(lambda x, a=a, p=p: (a * (x + p)) % p)\n        \n        # Bit-shift hash function\n        hash_functions.append(lambda x, a=a, p=p: ((x << a) + (x >> a)) % p)\n    \n    # Limit to 10 unique hash functions\n    return hash_functions[:num_hashes]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T15:18:53.439252Z","iopub.execute_input":"2024-12-08T15:18:53.439678Z","iopub.status.idle":"2024-12-08T15:18:53.451108Z","shell.execute_reply.started":"2024-12-08T15:18:53.439639Z","shell.execute_reply":"2024-12-08T15:18:53.449830Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"I will generate 10 different hash function cause bigger amaount of function is computationaly expensive for my set up (Kaggle notebook).","metadata":{}},{"cell_type":"code","source":"diverse_hash_functions = generate_diverse_hash_functions(num_hashes=10, max_value=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T15:18:55.464257Z","iopub.execute_input":"2024-12-08T15:18:55.464656Z","iopub.status.idle":"2024-12-08T15:18:55.470042Z","shell.execute_reply.started":"2024-12-08T15:18:55.464623Z","shell.execute_reply":"2024-12-08T15:18:55.468833Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"For the further experiment with configuration I will compare different types of functions and only linear ones.","metadata":{}},{"cell_type":"code","source":"linear_hash_functions = []\nfor a, b, p in [\n    (3, 7, 101),   # h1(x) = (3x + 7) % 101\n    (5, 11, 103),  # h2(x) = (5x + 11) % 103\n    (7, 13, 107),  # h3(x) = (7x + 13) % 107\n    (11, 17, 109), # h4(x) = (11x + 17) % 109\n    (13, 19, 113), # h5(x) = (13x + 19) % 113\n    (17, 23, 127), # h6(x) = (17x + 23) % 127\n    (19, 29, 131), # h7(x) = (19x + 29) % 131\n    (23, 31, 137), # h8(x) = (23x + 31) % 137\n    (29, 37, 139), # h9(x) = (29x + 37) % 139\n    (31, 41, 149)  # h10(x) = (31x + 41) % 149\n]:\n    linear_hash_functions.append(lambda x, a=a, b=b, p=p: (a * x + b) % p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:48:14.289038Z","iopub.execute_input":"2024-12-08T12:48:14.289366Z","iopub.status.idle":"2024-12-08T12:48:14.294700Z","shell.execute_reply.started":"2024-12-08T12:48:14.289338Z","shell.execute_reply":"2024-12-08T12:48:14.293932Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Async function for computing a user's signature\nasync def compute_user_signature(user_id, movies, hash_functions):\n    \"\"\"Compute the MinHash signature for a single user asynchronously.\"\"\"\n    signature = []\n    for hash_fn in hash_functions:\n        min_hash = float('inf')\n        for movie in movies:\n            hash_value = hash_fn(movie)\n            min_hash = min(min_hash, hash_value)\n        signature.append(min_hash)\n    return user_id, signature\n\nasync def generate_user_signatures(user_movie_map, hash_functions, batch_size=1000):\n    \"\"\"\n    Generate MinHash signatures for all users using the given hash functions.\n    \n    Args:\n        user_movie_map: Dictionary mapping user IDs to sets of movie IDs.\n        hash_functions: List of (a, b, p) tuples defining the hash functions.\n        batch_size: Number of users to process in each batch.\n    \n    Returns:\n        Dictionary of user signatures.\n    \"\"\"\n    all_user_signatures = {}\n    user_ids = list(user_movie_map.keys())\n    \n    print(\"Generating MinHash signatures for users...\")\n    start_time = time.time()\n    \n    # Async signature computation with batched processing\n    with tqdm(total=len(user_ids), desc=\"User Signatures\", unit=\"user\") as pbar:\n        for i in range(0, len(user_ids), batch_size):\n            batch_ids = user_ids[i:i + batch_size]\n            \n            # Create async tasks for batch processing\n            tasks = [\n                compute_user_signature(user_id, user_movie_map[user_id], hash_functions)\n                for user_id in batch_ids\n            ]\n            \n            # Process the batch\n            batch_results = await asyncio.gather(*tasks)\n            \n            # Collect signatures for each user in the batch\n            for user_id, signature in batch_results:\n                all_user_signatures[user_id] = signature\n            \n            # Update progress bar\n            pbar.update(len(batch_ids))\n    \n    print(f\"All user signatures computed in {time.time() - start_time:.2f} seconds.\")\n    return all_user_signatures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T15:19:24.340217Z","iopub.execute_input":"2024-12-08T15:19:24.340673Z","iopub.status.idle":"2024-12-08T15:19:24.350826Z","shell.execute_reply.started":"2024-12-08T15:19:24.340635Z","shell.execute_reply":"2024-12-08T15:19:24.349591Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"I generated user signatures using onlu linear hash functions and separately 10 different types of hash functions.","metadata":{}},{"cell_type":"code","source":"# Generate user signatures\nlinear_user_signatures = await generate_user_signatures(user_movie_map, linear_hash_functions)\ndiverse_user_signatures = await generate_user_signatures(user_movie_map, diverse_hash_functions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T15:20:11.203696Z","iopub.execute_input":"2024-12-08T15:20:11.204110Z","iopub.status.idle":"2024-12-08T16:17:43.670145Z","shell.execute_reply.started":"2024-12-08T15:20:11.204073Z","shell.execute_reply":"2024-12-08T16:17:43.668637Z"}},"outputs":[{"name":"stdout","text":"Generating MinHash signatures for users...\n","output_type":"stream"},{"name":"stderr","text":"User Signatures: 100%|██████████| 138493/138493 [57:32<00:00, 40.11user/s]","output_type":"stream"},{"name":"stdout","text":"All user signatures computed in 3452.44 seconds.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"`save_user_signatures_to_files` and `load_user_signatures_from_files` are created for saving runtime `user_signatures` into the files and uploading if there is a need.","metadata":{}},{"cell_type":"code","source":"async def save_user_signatures_to_files(user_signatures, output_dir, selector='linear'):\n    filename = f\"{output_dir}/user_signatures_{selector}.json\"\n    with open(filename, \"w\") as f:\n        json.dump(user_signatures, f, indent=4)\n    print(f\"User signatures saved to {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:59:07.578735Z","iopub.execute_input":"2024-12-08T12:59:07.579015Z","iopub.status.idle":"2024-12-08T12:59:07.583965Z","shell.execute_reply.started":"2024-12-08T12:59:07.578990Z","shell.execute_reply":"2024-12-08T12:59:07.583075Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load user signatures from the file\ndef load_user_signatures_from_files(output_dir, selector='linear'):\n    user_signatures = {}\n    filename = f\"{output_dir}/user_signatures_{selector}.json\"\n    with open(filename, \"r\") as f:\n        user_signatures = json.load(f)\n    print(f\"User signatures from loaded from {filename}\")\n    # Cast values to integer values: when dumping a dictionary into json values are written as strings\n    user_signatures = {int(user_id): list(map(int, signature)) for user_id, signature in user_signatures.items()}\n    return user_signatures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:51.196093Z","iopub.execute_input":"2024-12-08T22:03:51.196754Z","iopub.status.idle":"2024-12-08T22:03:51.201710Z","shell.execute_reply.started":"2024-12-08T22:03:51.196713Z","shell.execute_reply":"2024-12-08T22:03:51.200820Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"output_dir = '/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:51.202750Z","iopub.execute_input":"2024-12-08T22:03:51.203007Z","iopub.status.idle":"2024-12-08T22:03:51.213500Z","shell.execute_reply.started":"2024-12-08T22:03:51.202976Z","shell.execute_reply":"2024-12-08T22:03:51.212684Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Selector in files writing/reading functions `selector='linear'` is for distinguish different `user_signatures` for an experiment. In 1.3 will be used only one set of `user_signatures` that will show better metrics in the experiment. ","metadata":{}},{"cell_type":"code","source":"await save_user_signatures_to_files(linear_user_signatures, output_dir)\nawait save_user_signatures_to_files(diverse_user_signatures, output_dir, 'diverse')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:59:07.594696Z","iopub.execute_input":"2024-12-08T12:59:07.594956Z","iopub.status.idle":"2024-12-08T12:59:09.553030Z","shell.execute_reply.started":"2024-12-08T12:59:07.594931Z","shell.execute_reply":"2024-12-08T12:59:09.552128Z"}},"outputs":[{"name":"stdout","text":"User signatures saved to /kaggle/working/user_signatures_linear.json\nUser signatures saved to /kaggle/working/user_signatures_diverse.json\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"linear_user_signatures = load_user_signatures_from_files(output_dir)\ndiverse_user_signatures = load_user_signatures_from_files(output_dir, 'diverse')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:20:36.020714Z","iopub.execute_input":"2024-12-08T21:20:36.021094Z","iopub.status.idle":"2024-12-08T21:20:36.847834Z","shell.execute_reply.started":"2024-12-08T21:20:36.021061Z","shell.execute_reply":"2024-12-08T21:20:36.847034Z"}},"outputs":[{"name":"stdout","text":"User signatures from loaded from /kaggle/working/user_signatures_diverse.json\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here I'm comparing the signatures pairwise and evaluting metrics.","metadata":{}},{"cell_type":"code","source":"# Compute true Jaccard similarity\ndef compute_true_jaccard(set1, set2):\n    intersection = len(set1 & set2)\n    union = len(set1 | set2)\n    return intersection / union if union != 0 else 0\n\n# Compute estimated similarity from MinHash signatures\ndef compute_minhash_similarity(signature1, signature2):\n    matches = sum(1 for h1, h2 in zip(signature1, signature2) if h1 == h2)\n    return matches / len(signature1)\n\nasync def compare_user_pair(user1, user2, user_signatures, threshold):\n    \"\"\"\n    Compare a pair of users and compute metrics asynchronously.\n    \"\"\"\n    # Compute True Jaccard similarity\n    true_jaccard = compute_true_jaccard(user_movie_map[user1], user_movie_map[user2])\n    \n    # Compute MinHash Estimated Jaccard Similarity\n    estimated_jaccard = compute_minhash_similarity(user_signatures[user1], user_signatures[user2])\n    \n    # Check threshold conditions\n    true_positive = estimated_jaccard >= threshold and true_jaccard >= threshold\n    false_positive = estimated_jaccard >= threshold and true_jaccard < threshold\n    false_negative = estimated_jaccard < threshold and true_jaccard >= threshold\n\n    # Log comparison results\n    return {\n        \"true_jaccard\": true_jaccard,\n        \"estimated_jaccard\": estimated_jaccard,\n        \"true_positive\": true_positive,\n        \"false_positive\": false_positive,\n        \"false_negative\": false_negative,\n    }\n\nasync def evaluate_all_pairs_async(user_signatures, thresholds, batch_size=1000):\n    \"\"\"\n    Evaluate MinHash signatures for all user pairs asynchronously for multiple thresholds.\n    \"\"\"\n    results = {}\n    user_ids = list(user_signatures.keys())\n    total_users = len(user_ids)\n    total_pairs = total_users * (total_users - 1) // 2\n\n    print(f\"Total users: {total_users}, Total pairs: {total_pairs}\")\n\n    for threshold in thresholds:\n        print(f\"Evaluating for threshold: {threshold}...\")\n\n        # Create tasks for all user pairs\n        tasks = []\n        for user1, user2 in combinations(user_ids, 2):\n            tasks.append(compare_user_pair(user1, user2, user_signatures, threshold))\n\n        # Process tasks in batches with progress tracking\n        results_list = []\n        with tqdm(total=len(tasks), desc=f\"Processing pairs for threshold {threshold}\", unit=\"pair\") as pbar:\n            for i in range(0, len(tasks), batch_size):\n                task_batch = tasks[i:i + batch_size]\n                batch_results = await asyncio.gather(*task_batch)\n                results_list.extend(batch_results)\n                pbar.update(len(task_batch))  # Update progress bar\n\n        # Aggregate results\n        true_positives = sum(res[\"true_positive\"] for res in results_list)\n        false_positives = sum(res[\"false_positive\"] for res in results_list)\n        false_negatives = sum(res[\"false_negative\"] for res in results_list)\n        all_true_similarities = [res[\"true_jaccard\"] for res in results_list]\n        all_estimated_similarities = [res[\"estimated_jaccard\"] for res in results_list]\n\n        # Compute metrics\n        precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n        recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n        f1 = (2 * precision * recall / (precision + recall)) if precision + recall > 0 else 0\n        mae = mean_absolute_error(all_true_similarities, all_estimated_similarities)\n\n        print(f\"Completed evaluation for threshold {threshold}: precision: {precision}, recall: {recall}, f1_score: {f1}, mae: {mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:59:32.184441Z","iopub.execute_input":"2024-12-08T11:59:32.185306Z","iopub.status.idle":"2024-12-08T11:59:32.196916Z","shell.execute_reply.started":"2024-12-08T11:59:32.185271Z","shell.execute_reply":"2024-12-08T11:59:32.196090Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Define thresholds\nthresholds = [0.3, 0.5, 0.7]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:59:37.164417Z","iopub.execute_input":"2024-12-08T11:59:37.164809Z","iopub.status.idle":"2024-12-08T11:59:37.169262Z","shell.execute_reply.started":"2024-12-08T11:59:37.164777Z","shell.execute_reply":"2024-12-08T11:59:37.168133Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"To short off the process of comparing all signatures pairs I decided to pick a subset and run an experiment on it. The subset will be picked randomly according to the desired `max_pairs` value.","metadata":{}},{"cell_type":"code","source":"# Select a subset of user_signatures with approximately max_pairs\ndef get_subset_user_signatures(user_signatures, max_pairs=200000):\n    user_ids = list(user_signatures.keys())\n    total_users = len(user_ids)\n    \n    # Calculate how many users are required for max_pairs\n    subset_size = 1\n    while subset_size * (subset_size - 1) // 2 <= max_pairs:\n        subset_size += 1\n    subset_size -= 1  # Step back to ensure we don't exceed max_pairs\n\n    print(f\"Selecting {subset_size} users for approximately {max_pairs} pairs.\")\n    \n    # Randomly sample user IDs\n    sampled_user_ids = random.sample(user_ids, subset_size)\n    \n    # Create a subset of user_signatures\n    subset_signatures = {user_id: user_signatures[user_id] for user_id in sampled_user_ids}\n    return subset_signatures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:59:38.837312Z","iopub.execute_input":"2024-12-08T11:59:38.837696Z","iopub.status.idle":"2024-12-08T11:59:38.844712Z","shell.execute_reply.started":"2024-12-08T11:59:38.837661Z","shell.execute_reply":"2024-12-08T11:59:38.843698Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Get a subset of user_signatures\nsubset_linear_user_signatures = get_subset_user_signatures(linear_user_signatures, max_pairs=2000000)\nsubset_diverse_user_signatures = get_subset_user_signatures(diverse_user_signatures, max_pairs=2000000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:15:14.009272Z","iopub.execute_input":"2024-12-08T12:15:14.009688Z","iopub.status.idle":"2024-12-08T12:15:14.023235Z","shell.execute_reply.started":"2024-12-08T12:15:14.009654Z","shell.execute_reply":"2024-12-08T12:15:14.022146Z"}},"outputs":[{"name":"stdout","text":"Selecting 2000 users for approximately 2000000 pairs.\nSelecting 2000 users for approximately 2000000 pairs.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Run async evaluation with tracing and progress tracking\nawait evaluate_all_pairs_async(subset_linear_user_signatures, thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:15:15.934505Z","iopub.execute_input":"2024-12-08T12:15:15.934890Z","iopub.status.idle":"2024-12-08T12:19:13.351248Z","shell.execute_reply.started":"2024-12-08T12:15:15.934857Z","shell.execute_reply":"2024-12-08T12:19:13.350451Z"}},"outputs":[{"name":"stdout","text":"Total users: 2000, Total pairs: 1999000\nEvaluating for threshold: 0.3...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.3: 100%|██████████| 1999000/1999000 [01:18<00:00, 25553.53pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.3: precision: 0.010454081041510865, recall: 0.9215413184772516, f1_score: 0.020673637727045488, mae: 0.2936536385124049\nEvaluating for threshold: 0.5...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.5: 100%|██████████| 1999000/1999000 [01:15<00:00, 26479.18pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.5: precision: 0.0015205543718719693, recall: 0.8118811881188119, f1_score: 0.003035423765517216, mae: 0.2936536385124049\nEvaluating for threshold: 0.7...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.7: 100%|██████████| 1999000/1999000 [01:15<00:00, 26509.06pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.7: precision: 0.00023634058827320972, recall: 0.8870967741935484, f1_score: 0.0004725552782276599, mae: 0.2936536385124049\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Run async evaluation with tracing and progress tracking\nawait evaluate_all_pairs_async(subset_diverse_user_signatures, thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:19:13.352353Z","iopub.execute_input":"2024-12-08T12:19:13.352708Z","iopub.status.idle":"2024-12-08T12:23:03.703435Z","shell.execute_reply.started":"2024-12-08T12:19:13.352678Z","shell.execute_reply":"2024-12-08T12:23:03.702411Z"}},"outputs":[{"name":"stdout","text":"Total users: 2000, Total pairs: 1999000\nEvaluating for threshold: 0.3...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.3: 100%|██████████| 1999000/1999000 [01:14<00:00, 26993.33pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.3: precision: 0.028887808970796524, recall: 0.8313908313908314, f1_score: 0.05583553604723742, mae: 0.13670679434116426\nEvaluating for threshold: 0.5...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.5: 100%|██████████| 1999000/1999000 [01:13<00:00, 27038.91pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.5: precision: 0.010281556469471686, recall: 0.7367044463818657, f1_score: 0.02028008112032448, mae: 0.13670679434116426\nEvaluating for threshold: 0.7...\n","output_type":"stream"},{"name":"stderr","text":"Processing pairs for threshold 0.7: 100%|██████████| 1999000/1999000 [01:14<00:00, 26984.07pair/s]\n","output_type":"stream"},{"name":"stdout","text":"Completed evaluation for threshold 0.7: precision: 0.0018585921164717726, recall: 0.75, f1_score: 0.0037079953650057938, mae: 0.13670679434116426\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{}"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"**Linear Hash Functions**\n| Metric        | Threshold (0.3) | Threshold (0.5) | Threshold (0.7) |\n|---------------|-----------------|-----------------|-----------------|\n| **Precision** | 0.01045         | 0.00153         | 0.00026         |\n| **Recall**    | 0.92154         | 0.81181         | 0.88709         |\n| **F1 Score**  | 0.02067         | 0.00305         | 0.00047         |\n| **MAE**       | 0.29365         | 0.29365         | 0.29365         |\n\n**Different Hash Functions**\n| Metric        | Threshold (0.3) | Threshold (0.5) | Threshold (0.7) |\n|---------------|-----------------|-----------------|-----------------|\n| **Precision** | 0.02888         | 0.01028         | 0.00185         |\n| **Recall**    | 0.83139         | 0.73670         | 0.75000         |\n| **F1 Score**  | 0.05583         | 0.02020         | 0.00370         |\n| **MAE**       | 0.13670         | 0.13670         | 0.13670         |\n\n**Observations:**\n1. **Precision**: Different hash functions show significantly higher precision than linear hash functions across all thresholds. This suggests that different hash functions are better at reducing false positives, as they capture more unique and independent aspects of the data.\n3. **Recall**: Linear hash functions achieve higher recall, especially at lower thresholds (e.g., 0.3). This indicates that linear hash functions are better at identifying similar user pairs but might introduce more false positives.\n4. **F1 Score**: The F1 score for diverse hash functions is consistently higher, particularly at threshold 0.3, where the improvement is most pronounced. This balance between precision and recall highlights the practical effectiveness of different hash functions.\n5. **MAE**: The MAE for different hash functions is significantly lower than for linear hash functions. This demonstrates that the estimated Jaccard similarity from different hash functions is much closer to the true Jaccard similarity, improving accuracy.\n\n**Conclusions**:\n\nFor 1.3 I will use different types of hash functions cause they demonstrated better accuracy that only linear functions.","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Locality-Sensitive Hashing (LSH)\n\nNow that you have generated MinHash user signatures, apply Locality-Sensitive Hashing (LSH) to cluster similar users.\n\n1. **Bucket Creation:** For each user, divide the MinHash signature into bands and hash each band to form buckets. Users with similar bands should fall into the same buckets.\n   - **Debugging Tip:** After creating buckets, check a few bucket contents to verify that multiple users are being grouped in the same buckets.\n   \n2. **Query:** For a given user, identify the **two most similar users** based on their bucket placement. If a user doesn’t have any similar users in their bucket, adjust the parameters until similar users are found.\n\n3. **Movie Recommendation Logic:**\n   - If both similar users have rated a movie, recommend this movie based on the **average rating**.\n   - If there are no commonly rated movies, recommend the top-rated movies of the most similar user.\n\n4. **Final Recommendation:** Provide **at most five movies** to the user. \n\nExample recommendation logic for a user:\n\n| User | Movie Title         | Rating |\n|------|----------------------|--------|\n| A    | Inception           | 4.5    |\n| A    | Titanic             | 4.2    |\n| A    | Avatar              | 2.8    |\n| B    | Inception           | 4.6    |\n| B    | The Matrix          | 3.9    |\n| B    | Toy Story           | 4.7    |\n| C    | Titanic             | 3.8    |\n| C    | Avatar              | 4.3    |\n| C    | Shrek               | 4.1    |\n\nIf User A and User B are identified as the two most similar users to User X, the recommended movies would be:\n1. **Common Movies:** \"Inception\" (average rating: 4.55).\n2. **Top-rated from Most Similar User:** \"Toy Story\" (4.7) from User B and \"Titanic\" (4.2) from User A.\n3. If fewer than 5 movies are found, complete the list using other high-rated movies by the most similar users.","metadata":{}},{"cell_type":"code","source":"user_signatures = load_user_signatures_from_files(output_dir, 'diverse')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:03:53.547005Z","iopub.execute_input":"2024-12-08T22:03:53.547367Z","iopub.status.idle":"2024-12-08T22:03:54.252789Z","shell.execute_reply.started":"2024-12-08T22:03:53.547335Z","shell.execute_reply":"2024-12-08T22:03:54.251842Z"}},"outputs":[{"name":"stdout","text":"User signatures from loaded from /kaggle/working/user_signatures_diverse.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Define LSH Class\nclass LSH:\n    def __init__(self, num_bands):\n        \"\"\"\n        Initialize the LSH instance.\n        Args:\n            num_bands (int): Number of bands to split the signatures into.\n        \"\"\"\n        self.num_bands = num_bands\n        self.buckets = [{} for _ in range(num_bands)]  # List of dictionaries, one for each band\n\n    async def add_user_signature(self, user_id, signature):\n        rows_per_band = len(signature) // self.num_bands\n        subvecs = [\n            signature[i:i + rows_per_band]\n            for i in range(0, len(signature), rows_per_band)\n        ]\n        for band_index, subvec in enumerate(subvecs):\n            subvec_key = ','.join(map(str, subvec))\n            if subvec_key not in self.buckets[band_index]:\n                self.buckets[band_index][subvec_key] = []\n            self.buckets[band_index][subvec_key].append(user_id)\n\n    async def add_all_signatures(self, user_signatures):\n        tasks = [\n            self.add_user_signature(user_id, signature)\n            for user_id, signature in user_signatures.items()\n        ]\n        await tqdm.gather(*tasks, desc=\"Adding user signatures\", unit=\"user\")\n\n    async def find_similar_users(self, target_user_id, user_signatures, top_similar_users=1000):\n        target_signature = user_signatures[target_user_id]\n        rows_per_band = len(target_signature) // self.num_bands\n        subvecs = [\n            target_signature[i:i + rows_per_band]\n            for i in range(0, len(target_signature), rows_per_band)\n        ]\n\n        similar_users = set()\n        for band_index, subvec in enumerate(subvecs):\n            subvec_key = ','.join(map(str, subvec))\n            if subvec_key in self.buckets[band_index]:\n                similar_users.update(self.buckets[band_index][subvec_key])\n\n        similar_users.discard(target_user_id)\n\n        # Rank similar users by Jaccard similarity\n        def jaccard_similarity(sig1, sig2):\n            return sum(1 for a, b in zip(sig1, sig2) if a == b) / len(sig1)\n\n        ranked_users = sorted(\n            similar_users,\n            key=lambda user: jaccard_similarity(\n                user_signatures[target_user_id], user_signatures[user]\n            ),\n            reverse=True,\n        )\n\n        return ranked_users[:top_similar_users]\n\nasync def recommend_movies(target_user_id, similar_users, ratings, top_k=5):\n    \"\"\"\n    Generate movie recommendations based on similar users.\n\n    Args:\n        target_user_id: ID of the user for whom recommendations are being generated.\n        similar_users: List of similar user IDs.\n        ratings: DataFrame containing user ratings.\n        top_k: Maximum number of movies to recommend.\n\n    Returns:\n        List of recommended movies.\n    \"\"\"\n    # Ratings for the target user\n    target_user_ratings = ratings[ratings[\"userId\"] == target_user_id].set_index(\"movieId\")[\"rating\"]\n    target_user_movies = set(target_user_ratings.index)\n\n    # Ratings for similar users\n    similar_users_ratings = ratings[ratings[\"userId\"].isin(similar_users)]\n    similar_users_ratings = similar_users_ratings.groupby(\"movieId\")[\"rating\"].mean()\n\n    # Step 1: Find common movies\n    common_movies = target_user_movies.intersection(similar_users_ratings.index)\n    common_movies_avg = {\n        movie: (target_user_ratings[movie] + similar_users_ratings[movie]) / 2\n        for movie in common_movies\n    }\n\n    # Step 2: Find top-rated movies from similar users\n    unique_movies = similar_users_ratings.drop(index=common_movies, errors='ignore')\n    top_movies_from_similar_users = unique_movies.sort_values(ascending=False).head(top_k)\n\n    # Step 3: Combine results\n    recommendations = (\n        sorted(common_movies_avg.items(), key=lambda x: x[1], reverse=True)  # Common movies (sorted by avg rating)\n        + list(top_movies_from_similar_users.items())  # Top-rated movies from similar users\n    )\n\n    # Step 4: Limit to top_k recommendations\n    recommendations = recommendations[:top_k]\n\n    # Return only movie IDs\n    return [movie for movie, _ in recommendations]\n\nasync def run_lsh(user_signatures, ratings, num_bands, target_user_id, top_k=5, top_similar_users=1000):\n    \"\"\"\n    Run the LSH-based recommendation workflow.\n    Args:\n        user_signatures (dict): User signatures.\n        ratings (pd.DataFrame): Ratings dataset.\n        num_bands (int): Number of bands for LSH.\n        user_id (int): Target user ID.\n        top_k (int): Number of recommendations to return.\n    Returns:\n        list: List of recommended movie titles.\n    \"\"\"\n    \n    lsh = LSH(num_bands)\n\n    print(\"Adding user signatures to LSH buckets...\")\n    await lsh.add_all_signatures(user_signatures)\n\n    print(\"Finding similar users...\")\n    similar_users = await lsh.find_similar_users(target_user_id, user_signatures, top_similar_users=top_similar_users)\n    # print(f\"Similar Users for User {target_user_id}: {similar_users}\")\n\n    print(\"Generating recommendations...\")\n    recommended_movies = await recommend_movies(target_user_id, similar_users, ratings, top_k=top_k)\n    print(f\"Recommendations for User {target_user_id}: {recommended_movies}\")\n\n    return recommended_movies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:18:47.017642Z","iopub.execute_input":"2024-12-08T22:18:47.017946Z","iopub.status.idle":"2024-12-08T22:18:47.033122Z","shell.execute_reply.started":"2024-12-08T22:18:47.017921Z","shell.execute_reply":"2024-12-08T22:18:47.032276Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"To create LSH I used as a base this *source* and adapted to my user signatures.\n\n`Source`: https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/","metadata":{}},{"cell_type":"code","source":"def get_titles(recommended_movies, movie, rating, target_user_id):\n    \"\"\"\n    Map a list of movie IDs to their corresponding titles and average ratings.\n\n    Args:\n        recommended_movies: List of movie IDs to map.\n        movie: DataFrame containing movieId and title columns.\n        rating: DataFrame containing userId, movieId, and rating columns.\n        target_user_id: ID of the user for whom recommendations are being made.\n    \n    Returns:\n        DataFrame with movie IDs, titles, and average ratings.\n    \"\"\"\n    # Filter the rating dataframe for relevant movie IDs\n    relevant_ratings = rating[rating['movieId'].isin(recommended_movies)]\n    \n    # Calculate average ratings for the recommended movies\n    avg_ratings = relevant_ratings.groupby('movieId')['rating'].mean().reset_index()\n    avg_ratings.columns = ['movieId', 'Average Rating']\n    \n    # Merge movie titles and average ratings\n    recommended_movies_df = pd.DataFrame(recommended_movies, columns=[\"movieId\"])\n    mapped_movies = recommended_movies_df.merge(movie[['movieId', 'title']], on=\"movieId\", how=\"left\")\n    mapped_movies = mapped_movies.merge(avg_ratings, on=\"movieId\", how=\"left\")\n    \n    # Rename columns for clarity\n    mapped_movies = mapped_movies.rename(\n        columns={\"movieId\": \"Movie ID\", \"title\": \"Movie Title\", \"Average Rating\": \"Average Rating\"}\n    )\n    \n    # Select only the necessary columns\n    mapped_movies = mapped_movies[[\"Movie ID\", \"Movie Title\", \"Average Rating\"]]\n    \n    return mapped_movies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:33:01.964726Z","iopub.execute_input":"2024-12-08T22:33:01.965576Z","iopub.status.idle":"2024-12-08T22:33:01.972379Z","shell.execute_reply.started":"2024-12-08T22:33:01.965537Z","shell.execute_reply":"2024-12-08T22:33:01.971328Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Run LSH\ntarget_user_id = 1\nnum_bands = 5\nrecommended_movies = await run_lsh(user_signatures, rating, num_bands, target_user_id)\nrecommendations = get_titles(recommended_movies, movie, rating, target_user_id)\nrecommendations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:33:20.623223Z","iopub.execute_input":"2024-12-08T22:33:20.623597Z","iopub.status.idle":"2024-12-08T22:33:24.774877Z","shell.execute_reply.started":"2024-12-08T22:33:20.623567Z","shell.execute_reply":"2024-12-08T22:33:24.773882Z"}},"outputs":[{"name":"stdout","text":"Adding user signatures to LSH buckets...\n","output_type":"stream"},{"name":"stderr","text":"Adding user signatures: 100%|██████████| 138493/138493 [00:02<00:00, 47006.56user/s]\n","output_type":"stream"},{"name":"stdout","text":"Finding similar users...\nGenerating recommendations...\nRecommendations for User 1: [4993, 7153, 5952, 8507, 1196]\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"   Movie ID                                        Movie Title  Average Rating\n0      4993  Lord of the Rings: The Fellowship of the Ring,...        4.137925\n1      7153  Lord of the Rings: The Return of the King, The...        4.142382\n2      5952      Lord of the Rings: The Two Towers, The (2002)        4.107521\n3      8507                                      Freaks (1932)        3.801292\n4      1196  Star Wars: Episode V - The Empire Strikes Back...        4.188202","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie ID</th>\n      <th>Movie Title</th>\n      <th>Average Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4993</td>\n      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n      <td>4.137925</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7153</td>\n      <td>Lord of the Rings: The Return of the King, The...</td>\n      <td>4.142382</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5952</td>\n      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n      <td>4.107521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8507</td>\n      <td>Freaks (1932)</td>\n      <td>3.801292</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1196</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n      <td>4.188202</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"target_user_id = 2\nrecommended_movies = await run_lsh(user_signatures, rating, num_bands, target_user_id)\nrecommendations = get_titles(recommended_movies, movie, rating, target_user_id)\nrecommendations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:33:40.100944Z","iopub.execute_input":"2024-12-08T22:33:40.101296Z","iopub.status.idle":"2024-12-08T22:33:44.133690Z","shell.execute_reply.started":"2024-12-08T22:33:40.101252Z","shell.execute_reply":"2024-12-08T22:33:44.132719Z"}},"outputs":[{"name":"stdout","text":"Adding user signatures to LSH buckets...\n","output_type":"stream"},{"name":"stderr","text":"Adding user signatures: 100%|██████████| 138493/138493 [00:02<00:00, 48185.55user/s]\n","output_type":"stream"},{"name":"stdout","text":"Finding similar users...\nGenerating recommendations...\nRecommendations for User 2: [541, 260, 1196, 1214, 924]\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"   Movie ID                                        Movie Title  Average Rating\n0       541                                Blade Runner (1982)        4.133706\n1       260          Star Wars: Episode IV - A New Hope (1977)        4.190672\n2      1196  Star Wars: Episode V - The Empire Strikes Back...        4.188202\n3      1214                                       Alien (1979)        4.041784\n4       924                       2001: A Space Odyssey (1968)        3.955748","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie ID</th>\n      <th>Movie Title</th>\n      <th>Average Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>541</td>\n      <td>Blade Runner (1982)</td>\n      <td>4.133706</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>260</td>\n      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n      <td>4.190672</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1196</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n      <td>4.188202</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1214</td>\n      <td>Alien (1979)</td>\n      <td>4.041784</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>924</td>\n      <td>2001: A Space Odyssey (1968)</td>\n      <td>3.955748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"## 4. Algorithmic Question\n\nTwo brilliant strategists, Arya and Mario, are about to play a game with a sequence of numbers. Arya, as player 1, begins the game, while Mario, player 2, plays 2nd. Their goal is clear: to collect the highest possible score by taking numbers from either end of the sequence, one at a time. They will play in perfect synchronicity, each seeking the advantage.\n\nThe sequence represented as an array of `nums,` is laid out in front of them. Arya will start by selecting either the number at the beginning (`nums[0]`) or the end (`nums[nums.length - 1]`) of the array, adding that value to her score. This value is then removed from the beginning or the end of `nums`. Then, it’s Mario’s turn to do the same with the remaining sequence. The game proceeds this way, with each player taking numbers from either end until no numbers are left to claim. The player with the highest score wins.\n\nHowever, if they end in a tie, Arya, as the first to act, will claim victory by default.\n\nArya is now before you, asking for help to predict her chances. She wants to know, with her best possible choices, whether she can guarantee a win, assuming both players play with perfect skill.\n\n- a) Help Arya by providing a pseudocode for finding an optimal playing strategy, that is, a strategy that maximizes her value. (Hint: Use recursion, assuming that both players play optimally).\n\n- b) Write a Python program implementing her game strategy. Try different array lengths to test the algorithm.\n\n- c) Is the algorithm efficient? Prove that it is polynomial and provide an asymptotic time complexity bound, or show that it requires exponential time.\n\n- d) If the algorithm is exponential, explain how to make it polynomial and provide a pseudocode for it. Recompute the computational complexity of the updated algorithm.\n\n- e) Implement the algorithm in Python. Compare your result values with the previous algorithm. Also compare the running times.\n\n- f) Finally, consult LLM (ChatGPT, Claude AI, Gemini, Perplexity, etc.) to craft a third, optimized implementation and analyze its time complexity. Also, explain if the LLM is doing a good job and how you can evaluate whether the suggested solution works properly.\n\n**Examples**\n\n__Input 1__  \n```\nnums = [1, 5, 2]\n```\n\n__Output 1__  \n```\nfalse\n```\n\n__Explanation__: Arya’s optimal choices still lead her to a lower score than Mario’s, so she cannot guarantee victory.\n\n__Input 2__  \n```\nnums = [1, 5, 233, 7]\n```\n\n__Output 2__  \n```\ntrue\n```\n\n__Explanation__: Arya, by playing perfectly, can ensure she ends up with the highest score.\n\n---","metadata":{}},{"cell_type":"markdown","source":"**a) Help Arya by providing a pseudocode for finding an optimal playing strategy, that is, a strategy that maximizes her value. (Hint: Use recursion, assuming that both players play optimally).**","metadata":{}},{"cell_type":"markdown","source":"**BruteForceOptimalStrategy**\n\n```plaintext\nFunction BruteForceOptimalStrategy(nums, start, end, is_aryas_turn)\nInput:\n    nums: List of integers representing the numbers in the game\n    start: Current starting index of the array\n    end: Current ending index of the array\n    is_aryas_turn: Boolean indicating if it is Arya's turn (True for Arya, False for Mario)\n\nOutput:\n    Integer: The maximum score difference Arya can achieve\n\n    # Base case: if start exceeds end, no numbers are left to pick\n    if start > end:\n        return 0\n    end if\n\n    # If Arya's turn\n    if is_aryas_turn:\n        pick_start ← nums[start] + BruteForceOptimalStrategy(nums, start + 1, end, NOT is_aryas_turn)\n        pick_end ← nums[end] + BruteForceOptimalStrategy(nums, start, end - 1, NOT is_aryas_turn)\n        return Max(pick_start, pick_end)\n    # If Mario's turn\n    else:\n        pick_start ← -nums[start] + BruteForceOptimalStrategy(nums, start + 1, end, NOT is_aryas_turn)\n        pick_end ← -nums[end] + BruteForceOptimalStrategy(nums, start, end - 1, NOT is_aryas_turn)\n        return Min(pick_start, pick_end)\n    end if\n    end function\n```","metadata":{}},{"cell_type":"markdown","source":"**OptimalStrategy**\n\n```plaintext\nFunction OptimalStrategy(nums)\nInput:\n    nums: List of integers representing the numbers in the game\n\nOutput:\n    Boolean: True if Arya can guarantee a win, False otherwise\n\n    score_diff ← BruteForceOptimalStrategy(nums, 0, Length(nums) - 1, True)\n    return score_diff >= 0\n    end function\n```","metadata":{}},{"cell_type":"markdown","source":"**b) Write a Python program implementing her game strategy. Try different array lengths to test the algorithm.**","metadata":{}},{"cell_type":"code","source":"# exponential (brute force)\ndef brute_force_optimal_strategy(nums, start, end, is_aryas_turn):\n    # Base case: if start exceeds end, no numbers are left to pick\n    if start > end:\n        return 0\n\n    # If Arya's turn\n    if is_aryas_turn:\n        pick_start = nums[start] + brute_force_optimal_strategy(nums, start + 1, end, not is_aryas_turn)\n        pick_end = nums[end] + brute_force_optimal_strategy(nums, start, end - 1, not is_aryas_turn)\n        return max(pick_start, pick_end)\n    # If Mario's turn\n    else:  \n        pick_start = -nums[start] + brute_force_optimal_strategy(nums, start + 1, end, not is_aryas_turn)\n        pick_end = -nums[end] + brute_force_optimal_strategy(nums, start, end - 1, not is_aryas_turn)\n        return min(pick_start, pick_end)\n    \ndef optimal_strategy(nums):\n    score_diff = brute_force_optimal_strategy(nums, 0, len(nums) - 1, True)\n    # Arya wins if her score difference is non-negative (>= 0)\n    return score_diff >= 0\n\nnums1 = [1, 5, 2]\nnums2 = [1, 5, 233, 7]\nresult = optimal_strategy(nums1)\nprint(\"Will Arya win?\", result)\n\nresult = optimal_strategy(nums2)\nprint(\"Will Arya win?\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:26:13.574540Z","iopub.execute_input":"2024-12-08T16:26:13.575475Z","iopub.status.idle":"2024-12-08T16:26:13.584784Z","shell.execute_reply.started":"2024-12-08T16:26:13.575426Z","shell.execute_reply":"2024-12-08T16:26:13.583626Z"}},"outputs":[{"name":"stdout","text":"Will Arya win? False\nWill Arya win? True\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"**c) Is the algorithm efficient? Prove that it is polynomial and provide an asymptotic time complexity bound, or show that it requires exponential time.**","metadata":{}},{"cell_type":"markdown","source":"The algorithm is not efficient cause explores all possible conminations. The **BruteForceOptimalStrategy** algorithm has an <u>asymptotic time complexity upper bound</u> of $O(2^n)$, indicating exponential growth that is based on two recursive calls at each step (pick `start` or `end`). ","metadata":{}},{"cell_type":"markdown","source":"**d) If the algorithm is exponential, explain how to make it polynomial and provide a pseudocode for it. Recompute the computational complexity of the updated algorithm.**","metadata":{}},{"cell_type":"markdown","source":"To make the algorithm polinomial it is possible to break the problems into $O(n^2)$ unique subproblems (one for each (`start`, `end`) pair), and each is solved once and stored in some temporary table as `memo`. Reducing recomputing (`start`, `end`) pairs memorizing them makes the <u>asymptotic time complexity upper bound</u> $O(n^2)$.","metadata":{}},{"cell_type":"markdown","source":"**MemoizedOptimalStrategy**\n\n```plaintext\nFunction MemoizedOptimalStrategy(nums, start, end, memo, is_aryas_turn)\nInput:\n    nums: List of integers representing the numbers in the game\n    start: Current starting index of the array\n    end: Current ending index of the array\n    memo: Dictionary to store the results of subproblems\n    is_aryas_turn: Boolean indicating if it is Arya's turn (True for Arya, False for Mario)\n\nOutput:\n    Integer: The maximum score difference Arya can achieve\n\n    # Base case: if there is only one number left\n    if start == end:\n        return nums[start] if is_aryas_turn else -nums[start]\n    end if\n\n    # Check if the result is already in the memo\n    if (start, end, is_aryas_turn) is in memo:\n        return memo[(start, end, is_aryas_turn)]\n    end if\n\n    # If it is Arya's turn\n    if is_aryas_turn:\n        pick_start ← nums[start] + MemoizedOptimalStrategy(nums, start + 1, end, memo, NOT is_aryas_turn)\n        pick_end ← nums[end] + MemoizedOptimalStrategy(nums, start, end - 1, memo, NOT is_aryas_turn)\n        result ← Max(pick_start, pick_end)\n    else:  # If it is Mario's turn\n        pick_start ← -nums[start] + MemoizedOptimalStrategy(nums, start + 1, end, memo, NOT is_aryas_turn)\n        pick_end ← -nums[end] + MemoizedOptimalStrategy(nums, start, end - 1, memo, NOT is_aryas_turn)\n        result ← Min(pick_start, pick_end)\n    end if\n    \n    # Store the result in the memo\n    memo[(start, end, is_aryas_turn)] ← result\n    \n    return result\n    end function\n```","metadata":{}},{"cell_type":"markdown","source":"**OptimalStrategy**\n\n```plaintext\nFunction OptimalStrategy(nums)\nInput:\n    nums: List of integers representing the numbers in the game\n\nOutput:\n    Boolean: True if Arya can guarantee a win, False otherwise\n\n    # Initialize the memoization dictionary\n    memo ← {}\n    \n    # Calculate Arya's score difference starting with her turn\n    score_diff ← MemoizedOptimalStrategy(nums, 0, Length(nums) - 1, memo, True)\n    \n    # Arya wins if her score difference is non-negative\n    return score_diff >= 0\n    end function\n\n```","metadata":{}},{"cell_type":"markdown","source":"**e) Implement the algorithm in Python. Compare your result values with the previous algorithm. Also compare the running times.**","metadata":{}},{"cell_type":"code","source":"# polinomial (memorization of the steps)\ndef memoized_optimal_strategy(nums, start, end, memo, is_aryas_turn):\n    # Base case: if there's only one number left\n    if start == end:\n        return nums[start] if is_aryas_turn else -nums[start]\n    \n    # Check if the result is already in the memo\n    if (start, end, is_aryas_turn) in memo:\n        return memo[(start, end, is_aryas_turn)]\n    \n    if is_aryas_turn:\n        pick_start = nums[start] + memoized_optimal_strategy(nums, start + 1, end, memo, not is_aryas_turn)\n        pick_end = nums[end] + memoized_optimal_strategy(nums, start, end - 1, memo, not is_aryas_turn)\n        result = max(pick_start, pick_end)\n    else:  # Mario's turn\n        pick_start = -nums[start] + memoized_optimal_strategy(nums, start + 1, end, memo, not is_aryas_turn)\n        pick_end = -nums[end] + memoized_optimal_strategy(nums, start, end - 1, memo, not is_aryas_turn)\n        result = min(pick_start, pick_end)\n    \n    memo[(start, end, is_aryas_turn)] = result\n    return result\n\ndef optimal_strategy(nums):\n    memo = {}\n    score_diff = memoized_optimal_strategy(nums, 0, len(nums) - 1, memo, True)\n    return score_diff >= 0\n\nnums1 = [1, 5, 2]\nnums2 = [1, 5, 233, 7]\nresult = optimal_strategy(nums1)\nprint(\"Will Arya win?\", result)\n\nresult = optimal_strategy(nums2)\nprint(\"Will Arya win?\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:19:23.861260Z","iopub.execute_input":"2024-12-08T16:19:23.861773Z","iopub.status.idle":"2024-12-08T16:19:23.874357Z","shell.execute_reply.started":"2024-12-08T16:19:23.861731Z","shell.execute_reply":"2024-12-08T16:19:23.873198Z"}},"outputs":[{"name":"stdout","text":"Will Arya win? False\nWill Arya win? True\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"**f) Finally, consult LLM (ChatGPT, Claude AI, Gemini, Perplexity, etc.) to craft a third, optimized implementation and analyze its time complexity. Also, explain if the LLM is doing a good job and how you can evaluate whether the suggested solution works properly.**","metadata":{}},{"cell_type":"code","source":"def can_arya_win(nums):\n    n = len(nums)\n    # Precompute the cumulative sum for quick range sum queries\n    total_sum = sum(nums)\n    dp = [[0] * n for _ in range(n)]\n    \n    # Base case: when there's only one element\n    for i in range(n):\n        dp[i][i] = nums[i]\n    \n    # Fill the DP table for ranges of increasing length\n    for length in range(2, n + 1):\n        for i in range(n - length + 1):\n            j = i + length - 1\n            # Calculate the optimal score for Arya\n            pick_left = nums[i] + (sum(nums[i+1:j+1]) - dp[i+1][j])\n            pick_right = nums[j] + (sum(nums[i:j]) - dp[i][j-1])\n            dp[i][j] = max(pick_left, pick_right)\n    \n    # Arya wins if her score is greater than half the total sum\n    arya_score = dp[0][n-1]\n    return arya_score > total_sum / 2\n\n# Example usage\nnums1 = [1, 5, 2]\nnums2 = [1, 5, 233, 7]\nprint(can_arya_win(nums1))  # Output: True or False depending on input\nprint(can_arya_win(nums2))  # Output: True or False depending on input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:29:17.718127Z","iopub.execute_input":"2024-12-08T16:29:17.718653Z","iopub.status.idle":"2024-12-08T16:29:17.729475Z","shell.execute_reply.started":"2024-12-08T16:29:17.718611Z","shell.execute_reply":"2024-12-08T16:29:17.728093Z"}},"outputs":[{"name":"stdout","text":"False\nTrue\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"**ChatGPT Responce:**\n\nTo solve this problem optimally with a polynomial-time algorithm, we can use **Dynamic Programming (DP)**. Here's how we can approach it:\n\n**Problem Breakdown:**\n1. The game is about maximizing your score by choosing numbers from either end of the sequence.\n2. Both Arya and Mario play optimally, so each decision will impact the subsequent possible scores for both players.\n3. Arya needs to determine if she can guarantee a win.\n\n**Approach**:\nWe use a DP table where `dp[i][j]` represents the maximum score Arya can achieve when considering the subarray from index `i` to `j`. Here's the step-by-step explanation:\n\n- **Base Case**: If `i == j` (only one number left), Arya takes that number:\n  \\[\n  dp[i][i] = nums[i]\n  \\]\n\n- **Transition**:\n  When Arya picks from either end of the sequence:\n  - If she picks `nums[i]`, Mario is left with the subarray `nums[i+1]...nums[j]`, and Arya's next optimal score is the remainder after Mario plays optimally.\n  - If she picks `nums[j]`, the same reasoning applies for the subarray `nums[i]...nums[j-1]`.\n  \\[\n  dp[i][j] = \\max(nums[i] + \\text{sum}[i+1][j] - dp[i+1][j], nums[j] + \\text{sum}[i][j-1] - dp[i][j-1])\n  \\]\n  Here, `sum[i][j]` is the sum of elements from `nums[i]` to `nums[j]` (used to compute Mario's optimal remaining score efficiently).\n\n- **Goal**: Arya wins if her score (calculated in `dp[0][n-1]`) is strictly greater than half the total sum of the array.\n\n\n**Explanation of Code:**\n1. **`dp[i][j]`**:\n   Tracks Arya’s best possible score for subarray `nums[i:j+1]`.\n2. **Precomputing Sums**:\n   The `sum(nums[i:j+1])` ensures Mario’s next score can be calculated quickly.\n3. **Final Decision**:\n   Arya wins if her computed score is greater than half of the total score.\n\n**Complexity:**\n- **Time Complexity**: \\(O(n^2)\\) due to the nested loops to compute the DP table.\n- **Space Complexity**: \\(O(n^2)\\) for the DP table. Can be optimized to \\(O(n)\\) using rolling arrays.\n\nThis ensures an optimal polynomial-time solution to the problem.","metadata":{}},{"cell_type":"markdown","source":"To evaluate whether the suggested solution works properly I can trace it on one of the test cases:","metadata":{}},{"cell_type":"markdown","source":"**Rules Recap**\n- **Arya (Player 1)**:\n  Arya always starts. She aims to maximize her score and chooses optimally.\n- **Mario (Player 2)**:\n  Mario plays second and also chooses optimally to maximize his score (or minimize Arya’s advantage).\n\nBoth players can pick from either **end of the sequence**.\n\n**Step-by-Step Breakdown for `nums = [1, 5, 233, 7]`**\n\n**Trace Table (Arya's Decisions)**\n\n|   | j=0            | j=1                      | j=2                        | j=3                       |\n|---|----------------|--------------------------|----------------------------|---------------------------|\n| i=0 | Pick 1         | Pick 5, remaining (0-0) | Pick 233, remaining (0-1)  | Pick 1, remaining (1-3)   |\n| i=1 |                | Pick 5                  | Pick 233, remaining (1-1)  | Pick 7, remaining (1-2)   |\n| i=2 |                |                          | Pick 233                   | Pick 233, remaining (3-3) |\n| i=3 |                |                          |                            | Pick 7                    |\n\n\nGoing through each subarray and show Arya’s and Mario’s actions. Here's how the decisions are made:\n\n**Subarrays of Length 1**\n- **i=0, j=0**: Arya picks `1`.\n- **i=1, j=1**: Arya picks `5`.\n- **i=2, j=2**: Arya picks `233`.\n- **i=3, j=3**: Arya picks `7`.\n\n**Subarrays of Length 2**\n- **i=0, j=1** (`[1, 5]`):\n  - Arya can pick `1` (leaving `5` for Mario) or `5` (leaving `1` for Mario).\n  - If Arya picks:\n    - `1`: Mario picks `5`, total score for Arya is `1`.\n    - `5`: Mario picks `1`, total score for Arya is `5`.\n  - **Arya picks `5` for the best score.**\n\n- **i=1, j=2** (`[5, 233]`):\n  - Arya can pick `5` (leaving `233` for Mario) or `233` (leaving `5` for Mario).\n  - If Arya picks:\n    - `5`: Mario picks `233`, total score for Arya is `5`.\n    - `233`: Mario picks `5`, total score for Arya is `233`.\n  - **Arya picks `233` for the best score.**\n\n- **i=2, j=3** (`[233, 7]`):\n  - Arya can pick `233` (leaving `7` for Mario) or `7` (leaving `233` for Mario).\n  - If Arya picks:\n    - `233`: Mario picks `7`, total score for Arya is `233`.\n    - `7`: Mario picks `233`, total score for Arya is `7`.\n  - **Arya picks `233` for the best score.**\n\n**Subarrays of Length 3**\n- **i=0, j=2** (`[1, 5, 233]`):\n  - Arya can pick:\n    - `1`: Mario is left with `[5, 233]`. Mario picks `233` (leaving `5`), Arya gets `1 + 5 = 6`.\n    - `233`: Mario is left with `[1, 5]`. Mario picks `5` (leaving `1`), Arya gets `233 + 1 = 234`.\n  - **Arya picks `233` for the best score.**\n\n- **i=1, j=3** (`[5, 233, 7]`):\n  - Arya can pick:\n    - `5`: Mario is left with `[233, 7]`. Mario picks `233` (leaving `7`), Arya gets `5 + 7 = 12`.\n    - `7`: Mario is left with `[5, 233]`. Mario picks `233` (leaving `5`), Arya gets `7 + 5 = 12`.\n  - **Arya picks `7` for the best score.**\n\n**Full Array**\n- **i=0, j=3** (`[1, 5, 233, 7]`):\n  - Arya can pick:\n    - `1`: Mario is left with `[5, 233, 7]`. Mario picks `233` (leaving `[5, 7]`), Arya can only secure `1 + 12 = 13`.\n    - `7`: Mario is left with `[1, 5, 233]`. Mario picks `233` (leaving `[1, 5]`), Arya can only secure `7 + 6 = 13`.\n  - **Arya picks `1` for the best outcome.**\n\n**Final Score**\n\nWith perfect play, Arya can calculate her best outcome and whether she can win based on the initial choice.\n\n**Key Takeaways for Decision Making:**\n1. Arya always looks ahead to minimize Mario's best possible score.\n2. Mario similarly plays optimally to force Arya into the worst-case scenario.\n3. The DP table encodes all subarray decisions so Arya can ensure she makes the correct first move to maximize her final score.","metadata":{}}]}